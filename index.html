<!DOCTYPE html>
<html lang="en">
    <head>
      <!-- Global site tag (gtag.js) - Google Analytics -->
        <script async src="https://www.googletagmanager.com/gtag/js?id=G-2D1SMX07P5"></script>
        <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'G-2D1SMX07P5');
        </script>

        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
        <meta name="description" content="" />
        <meta name="author" content="" />
        <title>Nicholas Sanso: Portfolio</title>

        <!-- Font Awesome icons (free version)-->
        <script src="https://use.fontawesome.com/releases/v5.15.3/js/all.js" crossorigin="anonymous"></script>
        <!-- Google fonts-->
        <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:500,700" rel="stylesheet" type="text/css" />
        <link href="https://fonts.googleapis.com/css?family=Muli:400,400i,800,800i" rel="stylesheet" type="text/css" />
        <!-- Core theme CSS (includes Bootstrap)-->
        <link href="css/styles.css" rel="stylesheet" />
    </head>
    <body id="page-top">
        <!-- Navigation-->
        <nav class="navbar navbar-expand-lg navbar-dark bg-primary fixed-top" id="sideNav">
            <a class="navbar-brand js-scroll-trigger" href="#page-top">
                <span class="d-block d-lg-none">Nicholas Sanso</span>
                <span class="d-none d-lg-block"><img class="img-fluid img-profile rounded-circle mx-auto mb-2" src="img\headshot.jpg" alt="" /></span>
            </a>
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button>
            <div class="collapse navbar-collapse" id="navbarResponsive">
                <ul class="navbar-nav">
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#about">About</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#portfolio">Portfolio</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#skills">Skills</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#education">Education</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="assets\resume_catherine_sanso.pdf" target=_blank">Resume</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#interests">Interests</a></li>

                </ul>
            </div>
        </nav>
        <!-- Page Content-->
        <div class="container-fluid p-0">
            <!-- About-->
            <section class="resume-section" id="about">
                <div class="resume-section-content">
                    <h1 class="mb-0">
                        Nicholas
                        <span class="text-primary">Sanso</span>
                    </h1>
                    <div class="subheading mb-5">
                        Data Scientist ·
                        <a href="mailto:nicksanso20@gmail.com">nicksanso20@gmail.com</a>
                    </div>
                    <p class="lead mb-5"><p>Nicholas Sanso is a Certified Public Accountant and Level III CFA Candidate. </p>
                    <p>Nicholas Sanso is a Data Scientist at General Assembly. He loves to distill complex data into actionable insights. This process, which allows him to perceive and shape the world around him, is the common thread running through his professional experiences. These experiences, first as a financial data assistant and later as a financial consultant, granted him the opportunity to buttress his analytical proficiencies with subject-matter expertise. This expertise, best encapsulated by his level three CFA candidacy, CPA license, and Tableau certifications, synergize to form a deep, but malleable skillset that he continues to grow.</p>
                    <div class="social-icons">
                        <a class="social-icon" href="https://www.linkedin.com/in/nicholas-sanso/" target=_blank><i class="fab fa-linkedin-in"></i></a>
                        <a class="social-icon" href="https://github.com/Nicholas-Sanso" target=_blank><i class="fab fa-github"></i></a>
                    </div>
                </div>
            </section>
            <hr class="m-0" />
            <!-- Experience-->
            <section class="resume-section" id="portfolio">
                <div class="resume-section-content">
                    <h2 class="mb-5">Portfolio</h2>
                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Subreddit Classification</h3>
                            <div class="subheading mb-3"> <a href="assets\Subreddit Classification.pdf" target="_blank">Project Overview</a> · <a href="https://github.com/catherinesanso/Speech-Emotion-Recognition" target=_blank>Github Repo</a> </div>
                            <img src="img\preprocessing_for_subreddit_classifier_2.png" width="450" height="250">
                            <br><br>
                            <p> The objective was to build a model that will use submission text complexity, submission engagement, and submission term (word) frequency to distinguish which subreddit a submission was posted to (r_investing or r_stocks).</p>
                            <p> A series of base models were generated using features from one of the three feature baskets, (text complexity, submission engagement, and submission term frequency).  </p>
                            <p> Stacked models outperformed all their component base models in the validation accuracy and cross validation mean metrics. Term frequency was the most predictive of the feature groupings.
The logistic regression models trained on submission text performed almost identically to the estimator trained exclusively on the submission text. 
Validation accuracy of AdaBoost model which used only metrics representing the complexity of the language of the features was 72.9%, showing the complexity and length of the words, sentences and document itself are indicative of which subreddit the document belongs to.
Validation accuracy of the Knn, RF, and Decision Tree models show engagement on the submission is indicative of which subreddit the post belongs to.

</p>
                      
                        </div>

                    </div>
                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Housing Sale Price</h3>
                            <div class="subheading mb-3"> <a href="assets\TSLA Time Series Forecasting.pdf" target="_blank">Project Overview</a> · <a href="https://github.com/catherinesanso/TSLA-Time-Series-Forecasts" target=_blank>Github Repo</a> </div>
                            <img src="img\house_sale_price.png" width="450" height="250">
                            <br><br>
                            <p>The objective was to create a model that will predict the sales price of housing in low and medium density residential areas.<\p>
                            <p>A series of preprocessing and feature engineering steps were undertaken. Among the most important preprocessing steps were dropping the observations that represented 
                                dissimilar types of housing (such as low density housing and boats). Dropping the columns that had nulls in more than 6% of the rows.  
                                Impute the missing values of features with less than 6% missing using a Random Forest model. 
                                Engineer a metric to represent the degree of concentration within the categories of a feature. The metric is the Herfindahl-Hirschman Index
                                traditonally used to calculate the degree of firm concentration in an industry, but applied to the categories of the feature. 
                                Engineer a metric to represent the correlation of a categorical variable with all the other categorical vairables. This was perforemd by 
                                calculating the sum of a feature's Cramer V with all the other features. Calculat the F-statistic of the feature to see if a change in the
                                feature leads to change in the mean of the dependent variable (these three metrics to prioritize which categorical vairables to include 
                                in the model). Standardize all the features and PCA the highly correlated ones. 
                                <\p>
                            <p> The model explains 77.15% of the variation in the dependent vaiable (saleprice). PCA components have very low correlation with other features.<\p>
                      
                        </div>


                    </div>
                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Facial Age Classifier</h3>
                            <div class="subheading mb-3"> <a href="assets\Red Facial Age Classifiers.pdf" target="_blank">Project Overview</a> · <a href="https://github.com/catherinesanso/Wine-Recommendation-System" target=_blank>Github Repo</a> </div>
                            <img src="img\age_facial_image.png" width="250" height="250">
                            <br><br>
                            <p>Success will be determined by whether I can create a model that outperforms the two base models. The base models are the randomly
                                classifying model which will be correct 12.5% of the time and the other base model is Google's Efficient Net model, which is a pre-trained
                                model created by Alphabet. 
<\p>
                            <p>Data was collected from kaggle which categorized the images by their ages from 0 to 99. These groupings were collapsed into 8 age categories.
                                These groupings led to imbalanced classes. Data augmentation techniques of rotating and flipping were then applied to help balance the classes.
                                The more underrepresented a class, the more rotated and flipped versions of the images were created until all classes had 2612 images.<\p>
                            <p>The increase in test data's loss function and drop in test's accuracy rate with the inclusion of the Dropout function to the model architecture indicates that 
                                there are probably a limited number of patterns that the model relies heavily on. The improvement in performance with the reduction in batch size indicates that the model may have been converging to a local minimum when minimizing the loss function during the (training) gradient descent process. 
                                Reducing batch size likely led to a more stochastic gradient descent, helping the model bypass local minimums. Considerations for model performance must be balanced against hardware requirements. MaxPooling2D’s contribution to reducing training time is indispensable for all CNN models.
                                A model that outperformed the base model was established.</p>
                        </div>
            </section>

            <hr class="m-0" />
            <!-- Skills-->
            <section class="resume-section" id="skills">
                <div class="resume-section-content">
                    <h2 class="mb-5">Skills</h2>
                    <div class="subheading mb-3">Technologies</div>
                    <p>- Python<br>
                      - SQL<br>                           
                      - Jupyter Notebook<br>
                      - GitHub<br>
                      - Tableau<br>
                      - Power BI<br>
                      - Google Suite<br>
                      - Office 365<br>
                    <div class="subheading mb-3">Python Libraries</div>
                    <p>- Pandas<br>
                      - NumPy<br>
                      - SciPy<br>                            
                      - Matplotlib<br>
                      - Seaborn<br>
                      - Scikit-Learn<br>
                      - Natural Language Toolkit (NLTK)<br>
                      - Beautiful Soup<br>
                      - Keras<br>                    
                      - TensorFlow<br>
                      - Statsmodels<br>
                
                    <div class="subheading mb-3">Competencies</div>
                    <p>- Data Cleaning<br>
                      - Exploratory Data Analysis<br>
                      - Feature engineering<br>
                      - Predictive Modeling<br>
                      - Data Visualization<br>
                      - NLP<br>
                      - Feature engineering<br>
            
                    <div class="subheading mb-3">Modeling Experience</div>
                    <p>- Supervised Learning: Linear/Logistic Regressions | Classifications | Ensemble Models (Random Forests, Bagging, Boosting, Stacking)<br>
                      - Natural Language Processing (NLP): Web scraping, APIs<br>
                      - Unsupervised Learning: Clustering (K-Means, DBSCAN) | Dimensionality Reduction (PCA) | Recommendation Systems | Transfer Learning<br>
                      - Neural Nets (NNs)<br>
                      - Time Series<br>
                      - Experimental Design & A/B Testing<br>

                    </div>
            </section>
                                
            <hr class="m-0" />
            <!-- Education-->
            <section class="resume-section" id="education">
                <div class="resume-section-content">
                    <h2 class="mb-5">Education</h2>
                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">General Assembly</h3>
                            <div class="subheading mb-3">Data Science Immersive</div>

                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">May 2023 - October 2023</span></div>
                    </div>
                    <div class="d-flex flex-column flex-md-row justify-content-between">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Macaulay Baruch</h3>
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary"> September 2013 - May 2017</span></div>
                </div>

        </div>
        <!-- Bootstrap core JS-->
        <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.0/dist/js/bootstrap.bundle.min.js"></script>
        <!-- Core theme JS-->
        <script src="js/scripts.js"></script>
    </body>
</html>
